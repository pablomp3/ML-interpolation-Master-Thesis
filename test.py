import torch
import analyze
import models
from torchvision.utils import save_image
from torchvision import transforms
from torchvision.transforms.functional import crop
import preprocess as prep
import numpy as np
import numpy
import midi
from PIL import Image
from midi_state_conversion import midiToNoteStateMatrix
from midi_state_conversion import noteStateMatrixToMidi
from midi_state_conversion import padStateMatrix
import midi

# pad to add to tracks in order to reach a shape of 43x44x2
pad_44x2 = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]
pad_64x2 = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]
pad_78x2 = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0],
            [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]

im_transform = transforms.Compose([
    transforms.Resize(64),
    transforms.ToTensor(),
])
def get_ims(im_ids): #['00001.jpg']
    ims = []
    for im_id in im_ids:
        im_path = IMAGE_PATH + im_id
        im = Image.open(im_path)
        print(im)
        im = crop(im, 30, 0, 178, 178)
        ims.append(im_transform(im))
    return ims

# --------------------------------------------------------
# ---------------------- M O D E -------------------------
# --------------------------------------------------------
generate = False
load_midi_and_convert = False
encoding_decoding_photo = False
encoding_decoding_song = True
interpolating_photo = False
interpolating_song = False
# --------------------------------------------------------
# --------------------------------------------------------
# --------------------------------------------------------

USE_CUDA = True
#MODEL = 'dfc-300'
MODEL = 'pablo'
IMAGE_PATH = 'checkpoints/'
MODEL_PATH = './checkpoints/' + MODEL
LOG_PATH = './logs/' + MODEL + '/log.pkl'
OUTPUT_PATH = './samples/'
PLOT_PATH = './plots/' + MODEL
LATENT_SIZE = 100

use_cuda = USE_CUDA and torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print('Using device', device)
#model = models.BetaVAE(latent_size=LATENT_SIZE).to(device)
model = models.DFCVAE(latent_size=LATENT_SIZE).to(device)
print('latent size:', model.latent_size)
#attr_map, id_attr_map = prep.get_attributes()

#model.load_model(file_path=test_path)
model.load_last_model(MODEL_PATH)

if generate:
    new_song = analyze.generate(model, 1, device)
    save_image(new_song, 'checkpoints/new_song.png', padding=0, nrow=10)

    print("generated by model:", type(new_song), new_song.shape)
    nump_song = np.asarray(new_song)
    print("generated by model as np:", type(nump_song), nump_song.shape)

    # change order of dimensions: (examples, 2, 64, 64) to (examples, 64, 64, 2)
    nump_song = np.einsum('ijkl->iklj', nump_song)
    print("reshaped: ", nump_song.shape)
    #print(nump_song)
    #nump_song = np.squeeze(nump_song)
    nump_song = nump_song[:,:,:,:2]
    print("squeezed:", nump_song.shape)

if load_midi_and_convert:
    from mido import MidiFile

    # ----------------- print notes of song 1 and save it --------------------------------
    song_name = '0a1b7f59058eb2fba0a5bf43295c638d_11328.midi_8_1.midi'
    mid = MidiFile('checkpoints/'+song_name)
    for i, track in enumerate(mid.tracks):
        print('Track {}: {}'.format(i, track.name))
        for msg in track:
            print(msg)
    state = midiToNoteStateMatrix('checkpoints/'+song_name) #43x64x2
    state = np.asarray(state)
    print("state of midi song: ", type(state), state.shape)
    #print(state)

    #state = nump_song
    #print("state of generated song: ", type(state), state.shape)
    #state = state[21:, :, 1:]
    print("state of squeezed generated song: ", state.shape, " and save as new track")

    # ----------------- load saved song and print notes of reconstructed song --------------------------------
    noteStateMatrixToMidi(state, name='checkpoints/new_track_110_2')
    mid = MidiFile('checkpoints/new_track_110_2.mid')
    for i, track in enumerate(mid.tracks):
        print('Track {}: {}'.format(i, track.name))
        for msg in track:
            print(msg)
    '''
    print("Read new track")
    song_name = 'checkpoints/new_track.mid'
    state = midiToNoteStateMatrix(song_name)
    state = np.asarray(state)
    print("state of new track: ", type(state), state.shape) #43x64x2 (360 bytes)
    '''

if encoding_decoding_photo:
    #new_song = analyze.generate(model, 1, device) #generate image sampled from latent space
    #print("model generated photo:", type(new_song), new_song.shape)
    #print(new_song)
    #print(new_song.type())
    #save_image(new_song, 'checkpoints/yes_song.png', padding=0, nrow=10)

    ''' input image to be encoded and decoded is
        torch tensor of [3, 64, 64]'''
    photo = ['000001.jpg']
    photo = get_ims(photo)
    print("input specs to encoder_decoder:", type(photo[0]), photo[0].shape) #class torch.tensor, size [3,64,64]
    print(photo[0])
    encoded_photo = analyze.get_z(photo[0], model, device)
    print("encoded photo z:", type(encoded_photo), encoded_photo.shape) #class torch.tensor, size [1,100]
    #print(encoded_photo)
    #print(encoded_photo.type())
    model.eval()
    with torch.no_grad():
        decoded_photo = model.decode(encoded_photo).cpu()
    print("decoded photo:", type(decoded_photo), decoded_photo.shape) #class torch.tensor, size [1,3,64,64]
    #print(decoded_photo)
    #print(decoded_photo.type())
    save_image(decoded_photo, 'checkpoints/decoded_song.png', padding=0, nrow=10)

if encoding_decoding_song:
    '''input song as numpy array [43, 64, 2] is padded to
    shape [64, 64, 2] and reconstructed back to midi'''
    prove_reshape_to_midi = False

    folder_name = 'checkpoints/test'
    song_name = 'ff61238332977860aaa35023ca5e0732_9944.midi_4_1.midi'

    target_length = 64
    pad = pad_64x2
    #---------------------------------------------------------#
    # target_length #  pad   # lowerBound # upperBound # span #
    #     44         pad_44x2      36           80        44  #
    #     64         pad_64x2      28           92        64  #
    #     78         pad_78x2      22           100       78  #
    #---------------------------------------------------------#
    state = midiToNoteStateMatrix(folder_name + '/' + song_name)  # shape 43x64x2
    state = padStateMatrix(folder_name, song_name, target_length, pad, save_as_midi=False) # shape 64x64x2
    print(state[10])

    '''prove that is possible reshape [64, 64, 2] to [2, 64, 64] for feeding the NN
    and then reshaping to [64, 64, 2] in order to convert the tensor back to midi'''
    state = np.einsum('ijk->kij', state) # shape 2x64x64
    state = state.astype(np.float32)  # set to float in order to keep data consistency
    print("reshaped to:", type(state), state.shape)
    #print(state)

    state = torch.from_numpy(state)  # convert state: numpy array to torch tensor
    print("numpy to torch tensor:")
    #print(state)
    print("song to encode:", type(state), state.shape)
    encoded_song = analyze.get_z(state, model, device)
    #print(state)
    print("encoded song z:", type(encoded_song), encoded_song.shape)
    #print(encoded_song)

    model.eval()
    with torch.no_grad():
        decoded_song = model.decode(encoded_song).cpu()
    print("decoded song:", type(decoded_song), decoded_song.shape)
    #print(decoded_song)


    nump_song = decoded_song.cpu().numpy()
    print("reshaped to:", type(nump_song), nump_song.shape)
    #print(nump_song)
    nump_song = np.squeeze(nump_song)
    #print(nump_song)
    print("squeezed to:", type(nump_song), nump_song.shape)
    nump_song = np.einsum('kij->ijk', nump_song) # shape 64x64x2 (as original)
    print("reshaped to:", type(nump_song), nump_song.shape)
    print(nump_song[10])
    noteStateMatrixToMidi(nump_song, folder_name + '/' + 'reshaped_3' + song_name) # save as midi

if interpolating_photo:
    ''' input image to be encoded and decoded is
            torch tensor of [3, 64, 64]'''
    photo = ['000001.jpg', '000002.jpg']
    photo = get_ims(photo)
    print("input specs to encoder_decoder:", type(photo[0]), photo[0].shape)  # class torch.tensor, size [3,64,64]
    print(photo[0])
    print("input specs to encoder_decoder:", type(photo[1]), photo[1].shape)  # class torch.tensor, size [3,64,64]
    print(photo[1])

    inter1 = analyze.linear_interpolate(photo[0], photo[1], model, device)
    print("interp1", type(inter1), [t.size() for t in inter1])
    for t in inter1:
        print(t.numpy().shape, type(t.numpy())) #numpy array of size (3, 64, 64) each
    #print(inter1)
    save_image(inter1, 'checkpoints/interpolate-dfc.png', padding=0, nrow=10)

if interpolating_song:
    '''photo = ['000001.jpg', '000002.jpg']
    photo = get_ims(photo)
    print("input specs to encoder_decoder:", type(photo[0]), photo[0].shape)  # class torch.tensor, size [3,64,64]
    print(photo[0])
    print("input specs to encoder_decoder:", type(photo[1]), photo[1].shape)  # class torch.tensor, size [3,64,64]
    print(photo[1])

    inter1 = analyze.linear_interpolate(photo[0], photo[1], model, device)
    save_image(inter1, 'checkpoints/interpolate-dfc.png', padding=0, nrow=10)'''

    folder_name = 'checkpoints/test'
    #song_name_1 = '0a1b7f59058eb2fba0a5bf43295c638d_11328.midi_12_3.midi'
    #song_name_2 = '0a4090c28d930bd10d3b58ae69e9f2f1_14597.midi_1_2.midi'
    song_name_1 = 'ff61238332977860aaa35023ca5e0732_9944.midi_4_1.midi'
    song_name_2 = 'ff61238332977860aaa35023ca5e0732_9944.midi_4_3.midi'
    target_length = 64
    pad = pad_64x2
    # ---------------------------------------------------------#
    # target_length #  pad   # lowerBound # upperBound # span #
    #     44         pad_44x2      36           80        44  #
    #     64         pad_64x2      28           92        64  #
    #     78         pad_78x2      22           100       78  #
    # ---------------------------------------------------------#
    state_1 = midiToNoteStateMatrix(folder_name + '/' + song_name_1)  # shape 43x64x2
    state_2 = midiToNoteStateMatrix(folder_name + '/' + song_name_2)  # shape 43x64x2
    state_1 = padStateMatrix(folder_name, song_name_1, target_length, pad, save_as_midi=False)  # shape 64x64x2
    state_2 = padStateMatrix(folder_name, song_name_2, target_length, pad, save_as_midi=False)  # shape 64x64x2

    '''prove that is possible reshape [64, 64, 2] to [2, 64, 64] for feeding the NN
    and then reshaping to [64, 64, 2] in order to convert the tensor back to midi'''
    state_1 = np.einsum('ijk->kij', state_1)  # shape 2x64x64
    state_2 = np.einsum('ijk->kij', state_2)  # shape 2x64x64
    state_1 = state_1.astype(np.float32)  # set to float in order to keep data consistency
    state_2 = state_2.astype(np.float32)  # set to float in order to keep data consistency
    print("reshaped to:", type(state_1), state_1.shape)
    print(state_1)
    # nump_song = np.einsum('kij->ijk', nump_song) # shape 64x64x2 (as original)
    # print("reshaped to:", type(nump_song), nump_song.shape)
    # noteStateMatrixToMidi(nump_song, folder_name + '/' + 'reshaped_' + song_name) # save as midi

    ''' input image to be encoded and decoded is
                torch tensor of [3, 64, 64] --> [78, 78, 2]'''

    '''
    print("original song shape:", type(state), np.asarray(state).shape)
    state = np.einsum('ijk->kij', np.asarray(state))
    print("reshaped song:", type(state), state.shape)
    state = torch.from_numpy(np.asarray(state)) # convert state: list to numpy array to torch tensor
    '''
    state_1 = torch.from_numpy(state_1)  # convert state: numpy array to torch tensor
    state_2 = torch.from_numpy(state_2)  # convert state: numpy array to torch tensor
    print("numpy to torch tensor:")
    print(state_1)
    print("song to encode:", type(state_1), state_1.shape)

    inter1 = analyze.linear_interpolate(state_1, state_2, model, device)
    k = 0
    for t in inter1:
        print(t.numpy().shape, type(t.numpy())) #numpy array of size (3, 64, 64) each
        nump_song = t.numpy()
        #print("reshaped to:", type(nump_song), nump_song.shape)
        nump_song = np.einsum('kij->ijk', nump_song)  # shape 64x64x2 (as original)
        print("reshaped to:", type(nump_song), nump_song.shape)
        #print(nump_song)
        noteStateMatrixToMidi(nump_song, folder_name + '/' + 'interp_' + str(k) + '_' + song_name_1)  # save as midi
        #noteStateMatrixToMidi(nump_song, folder_name + '/' + '2_interp_' + str(k) + song_name_1)  # save as midi
        k+=1
        print(k)


    '''encoded_song = analyze.get_z(state, model, device)
    print(state)
    print("encoded song z:", type(encoded_song), encoded_song.shape)
    print(encoded_song)

    model.eval()
    with torch.no_grad():
        decoded_song = model.decode(encoded_song).cpu()
    # decoded_song = model.decode(encoded_song)
    print("decoded song:", type(decoded_song), decoded_song.shape)
    print(decoded_song)

    nump_song = decoded_song.cpu().numpy()
    print("reshaped to:", type(nump_song), nump_song.shape)
    print(nump_song)
    nump_song = np.squeeze(nump_song)
    print(nump_song)
    print("squeezed to:", type(nump_song), nump_song.shape)
    nump_song = np.einsum('kij->ijk', nump_song)  # shape 64x64x2 (as original)
    print("reshaped to:", type(nump_song), nump_song.shape)
    print(nump_song)
    noteStateMatrixToMidi(nump_song, folder_name + '/' + 'reshaped_3' + song_name)  # save as midi'''